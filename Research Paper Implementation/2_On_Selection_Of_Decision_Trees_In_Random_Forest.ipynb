{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y1hnWHSnyALz"
   },
   "source": [
    "### Iris Dataset\n",
    "- Split the dataset into 3 parts - train, test, validation\n",
    "- Define K (maximum number of features to be considered for the split)= square root of number of columns (K = M**1/2)\n",
    "- Train the randomforest classifier(RF) with the data and max_features  = K\n",
    "- Take a single estimator from the classifier(RF1)\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "- Create a new object of random forest classifier(RFa)\n",
    "- Use the single estimator(RF1) from the previous object in the new object(RFa)\n",
    "- Predict using the same dataset and compare the outputs\n",
    "\n",
    "#### Conclusion : \n",
    "\n",
    "- The score of the 2 models are different (RF and RFa)\n",
    "- The process is repeated after creating a new model estimator (RFb) combining multiple estimators from the first model created (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "owPjygaOxCOZ"
   },
   "outputs": [],
   "source": [
    "#Import Statements\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from statistics import mean\n",
    "import copy \n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XgN0YrrIkC1r"
   },
   "source": [
    " ### Algorithm \n",
    " \n",
    "1) N- No of samples in dataset \n",
    "\n",
    "2) M-No of features in dataset \n",
    "\n",
    "3) K-no of features for spliting the node=SQRT(M) \n",
    "\n",
    "4) Initialize 3*L array for storing error rates - Here L=300(No of decision trees in random forest) \n",
    "\n",
    "5) Create a for loop with 10 iterations \n",
    "\n",
    "      5.1) Split dataset into 3 with .3 as training,.3 validation and .4 as testing \n",
    "      5.2)Create a random forest object and fit it with training data (No of decision trees=300,max_features=SQRT(M) \n",
    "      5.3)Create an empty RF object for SFS \n",
    "      5.4)Create a copy of already created RF object for SBS \n",
    "      5.5)Create an empty RF object for SRS \n",
    "      5.6) Create a for loop with L iterations \n",
    "      \n",
    "            5.6.1)Call the method for SFS ..Compute and store the error rates(In the 3*L array) of the newly created SFS random forest using testing dataset.  \n",
    "            5.6.2)Call the method for SFS ..Compute and store the error rates(In the 3*L array)  of the newly created SFS random forest using testing dataset.  \n",
    "            5.6.3)Call the method for SFS ..Compute and store the error rates(In the 3*L array)  of the newly created SFS random forest using testing dataset.  End both the for loop \n",
    " \n",
    " 6) Average the error rates for SFS,SBS and SRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ce1SCz19k_iE"
   },
   "source": [
    "### As per algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e8MtHLcelU9U"
   },
   "source": [
    "### Code for SFS\n",
    "**Method for Sequential Forward selection of Classifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wd_59FFInAJe"
   },
   "outputs": [],
   "source": [
    "def SFS_method(classifier_SFS,classifier):\n",
    "    SFS_estimators = []\n",
    "    error_rates_SFS = []\n",
    "    SFS_estimators_temp=[]\n",
    "    # creating a new list for adding new trees\n",
    "    dtreeList=list(range(dTree))\n",
    "    #Adding all other properties of the random forest\n",
    "    classifier_SFS.classes_ = classifier.classes_\n",
    "    classifier_SFS.n_classes_ = classifier.n_classes_\n",
    "    classifier_SFS.n_outputs_ = classifier.n_outputs_    \n",
    "    for i in range(dTree):\n",
    "        error_score_=999\n",
    "        estmaator_no=0\n",
    "        flag=1\n",
    "        classifier_SFS_temp=copy.deepcopy(classifier_SFS)\n",
    "        \n",
    "        for i in dtreeList:\n",
    "            # assigning the added trees to the empty RF object created for SFS\n",
    "            SFS_estimators_temp.append(classifier.estimators_[i])\n",
    "            # assigning the number of estimators to the SFS object\n",
    "            classifier_SFS_temp.estimators_ = SFS_estimators_temp\n",
    "           # print(SFS_estimators_temp)\n",
    "            classifier_SFS_temp.n_estimators = len(classifier_SFS_temp)\n",
    "            # predicting using the SFS estimator\n",
    "            y_pred = classifier_SFS_temp.predict(X_val)\n",
    "            \n",
    "            # calculating the missclassification score using validation set\n",
    "            error_score = zero_one_loss(y_val, y_pred,normalize=True)\n",
    "            #print(dtreeList)\n",
    "            #print(i)\n",
    "            #print(error_score)\n",
    "            if (error_score<error_score_):\n",
    "                error_score_=error_score                \n",
    "                estmaator_no=i\n",
    "                flag=0  \n",
    "                #print(error_score_,\"error_score_\",estmaator_no,\"estmaator_no\")\n",
    "            SFS_estimators_temp.remove(classifier.estimators_[i])\n",
    "            \n",
    "        if(flag==0):\n",
    "            SFS_estimators.append(classifier.estimators_[estmaator_no])\n",
    "            classifier_SFS.estimators_ = SFS_estimators            \n",
    "            classifier_SFS.n_estimators = len(classifier_SFS)\n",
    "            y_test_pred=classifier_SFS.predict(X_test)\n",
    "            error_score_test = zero_one_loss(y_test, y_test_pred,normalize=True)\n",
    "            error_rates_SFS.append(error_score_test)  \n",
    "            \n",
    "        dtreeList.remove(estmaator_no)            \n",
    "        SFS_estimators_temp=classifier_SFS.estimators_\n",
    "    # appending score to a list\n",
    "    \n",
    "    return error_rates_SFS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for SBS\n",
    "**Method for Backward sequential elemination of classifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method for Backward sequential elemination of classifiers\n",
    "#Input 2 Random Forest classifier\n",
    "def SBS_method(classifier_SBS,classifier):\n",
    "    \n",
    "    #length of  the initial random forest object \n",
    "    lengthSubforest=len(classifier_SBS.estimators_)\n",
    "    \n",
    "    #Copy the estimators of initial random forest \n",
    "    SBS_estimators = copy.deepcopy(classifier_SBS.estimators_)\n",
    "    \n",
    "    #Empty list to store error value\n",
    "    error_rates_SBS = []\n",
    "    \n",
    "    #Initial predict\n",
    "    # Predicting using the SBS estimator\n",
    "    y_test_pred=classifier_SBS.predict(X_test)\n",
    "            \n",
    "    # Calculating the missclassification score using validation set\n",
    "    error_score_test = zero_one_loss(y_test, y_test_pred,normalize=True)\n",
    "            \n",
    "    # Appending error score to a list\n",
    "    error_rates_SBS.append(error_score_test)\n",
    "    #print(error_rates_SBS,\"---error_rates_SBS\")\n",
    "    \n",
    "    \n",
    "    SBS_estimators_temp=copy.deepcopy(classifier_SBS.estimators_)\n",
    "    #print(SBS_estimators_temp,\"---SBS_estimators_temp\")\n",
    "    \n",
    "    # creating a new list for removing the trees\n",
    "    dtreeList=list(range(dTree))   \n",
    "    \n",
    "    for i in range(dTree):\n",
    "        error_score_=999\n",
    "        flag=1\n",
    "        \n",
    "        classifier_SBS_temp=copy.deepcopy(classifier_SBS)\n",
    "        \n",
    "        for i in SBS_estimators_temp:\n",
    "            \n",
    "            if(len(SBS_estimators_temp)<=1):\n",
    "                break\n",
    "            # List after removal of the tree from the orginal random forest to get better accuracy\n",
    "            #print(SBS_estimators_temp,\"---SBS_estimators_temp\")\n",
    "            #print(i)\n",
    "            remove_tree=i\n",
    "            SBS_estimators_temp.remove(i)\n",
    "            #print(SBS_estimators_temp,\"---SBS_estimators_temp after removal\")\n",
    "            \n",
    "            # Assigning the estimators to the SBS random forest object\n",
    "            classifier_SBS_temp.estimators_ = SBS_estimators_temp\n",
    "            #print(classifier_SBS_temp,\"---classifier_SBS_temp after removal\")\n",
    "        \n",
    "            # Assigning the length of estimators to the SBS random forest object\n",
    "            classifier_SBS_temp.n_estimators = len(classifier_SBS_temp)\n",
    "            #print(len(classifier_SBS_temp),\"---len(classifier_SBS_temp)\")\n",
    "            \n",
    "            # Predicting using the SBS estimator\n",
    "            y_pred = classifier_SBS_temp.predict(X_val)\n",
    "            #print(y_pred,\"---y_pred\")\n",
    "            \n",
    "            # Calculating the missclassification score using validation set\n",
    "            error_score = zero_one_loss(y_val, y_pred,normalize=True)\n",
    "            #print(error_score,\"---error_score\")\n",
    "            \n",
    "            #Storing the value  to be eleminated from the original ranndom forest that satisfies least error score\n",
    "            if (error_score<error_score_):\n",
    "                error_score_=error_score                \n",
    "                SBS_estimators=copy.deepcopy(SBS_estimators_temp)\n",
    "                flag=0  \n",
    "                \n",
    "            SBS_estimators_temp.append(remove_tree)\n",
    "            \n",
    "        if(flag==0):\n",
    "            \n",
    "            #print(len(SBS_estimators))\n",
    "            classifier_SBS.estimators_ = SBS_estimators            \n",
    "            classifier_SBS.n_estimators = len(classifier_SBS)\n",
    "\n",
    "            # Predicting using the SBS estimator\n",
    "            y_test_pred=classifier_SBS.predict(X_test)\n",
    "\n",
    "            # Calculating the missclassification score using validation set\n",
    "            error_score_test = zero_one_loss(y_test, y_test_pred,normalize=True)\n",
    "\n",
    "            # Appending error score to a list\n",
    "            error_rates_SBS.append(error_score_test)\n",
    "            #print(error_rates_SBS,\"---error_rates_SBS\")\n",
    "\n",
    "            lengthSubforest=len(classifier_SBS)            \n",
    "            #print(lengthSubforest,\"---lengthSubforest\")\n",
    "\n",
    "            SBS_estimators_temp=classifier_SBS.estimators_ \n",
    "                \n",
    "        else:\n",
    "            break\n",
    "               \n",
    "         \n",
    "\n",
    "    #Return th error list\n",
    "    return error_rates_SBS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for SRS\n",
    "**Method for random sequential selection of classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method for random sequential selection of classifiers\n",
    "def SRS_method(classifier_SRS,classifier):\n",
    "    #Empty array for estimators\n",
    "    SRS_estimators = []\n",
    "    #Array for storing error\n",
    "    error_rates_SRS = []\n",
    "    #List of indices of estimators in the initial random forest\n",
    "    dtreeList=list(range(dTree))\n",
    "    \n",
    "    #For loop to randomly select the estimators from random forest\n",
    "    for i in range(dTree):\n",
    "        #Choose random K value from the List of estimators\n",
    "        k=random.choice(dtreeList)\n",
    "        #print(k)\n",
    "        \n",
    "        # Append kth estimator to the array of estimators\n",
    "        SRS_estimators.append(classifier.estimators_[k])\n",
    "        \n",
    "        # Add the estimator to the random forest \n",
    "        classifier_SRS.estimators_ = SRS_estimators\n",
    "        \n",
    "        # Assigning the estimator number to RF object\n",
    "        classifier_SRS.n_estimators = len(classifier_SRS)\n",
    "        #print(len(classifier_SRS))\n",
    "        \n",
    "        #Providing RF object with variables same as that of original random forest \n",
    "        classifier_SRS.classes_ = classifier.classes_\n",
    "        classifier_SRS.n_classes_ = classifier.n_classes_\n",
    "        classifier_SRS.n_outputs_ = classifier.n_outputs_\n",
    "        \n",
    "        # Predicting using the new SRS random forest\n",
    "        y_pred = classifier_SRS.predict(X_test)\n",
    "        \n",
    "        # Calculating the error score\n",
    "        error_score = zero_one_loss(y_test, y_pred,normalize=True)\n",
    "        #print(error_score)\n",
    "        \n",
    "        # Appending score to a list\n",
    "        error_rates_SRS.append(error_score)\n",
    "        #print(error_rates_SRS)\n",
    "        \n",
    "        #Removing the already added tree indices from list of estimators that are to be added\n",
    "        dtreeList.remove(k) \n",
    "        #print(dtreeList)\n",
    "        \n",
    "    return error_rates_SRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for Data Retrieval and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set to split to Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split():    \n",
    "    #To split the dataset into 3 parts   \n",
    "    X_train, X_test, y_train, y_test= train_test_split(X_Data, y_Target, test_size=0.4)\n",
    "    X_train, X_val, y_train, y_val= train_test_split(X_train, y_train, test_size=0.5)\n",
    "    \n",
    "    return X_train,X_val,X_test,y_train,y_val,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iris Dataset from UCI\n",
    "#https://archive.ics.uci.edu/ml/datasets/iris\n",
    "def get_IrisData():\n",
    "    #Reading dataset from the csv file\n",
    "    df_iris=pd.read_csv('iris.csv')\n",
    "    print(\"Data Description\")\n",
    "    print(df_iris.describe())\n",
    "    #Randomozing the dataset rows\n",
    "    np.random.seed(1)\n",
    "    shuffled_index=np.random.permutation(df_iris.index)\n",
    "    df_iris=df_iris.loc[shuffled_index]\n",
    "    #NonUniform distribution of data\n",
    "    print(\"Data Distribution\")\n",
    "    df_iris['species'].value_counts().sort_index().plot.bar()\n",
    "    plt.show() \n",
    "    print(\"Nan Values if any\")\n",
    "    print(df_iris.isna().sum())\n",
    "    print(\"Data Types\")\n",
    "    print(df_iris.dtypes)\n",
    "    print(\"Data Set\")\n",
    "    print(df_iris.head(5))\n",
    "    #Convert dataset into taarget and attribute set\n",
    "    # axis 1 refers to the columns\n",
    "    X= df_iris.drop('species', axis = 1)\n",
    "    y=df_iris['species']\n",
    "    print(\"Iris Dataset\")\n",
    "    print(X.head(5))\n",
    "    print(\"Class Column\")\n",
    "    print(y.head(5))\n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Description\n",
      "       sepal_length  sepal_width  petal_length  petal_width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.054000      3.758667     1.198667\n",
      "std        0.828066     0.433594      1.764420     0.763161\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n",
      "Data Distribution\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan Values if any\n",
      "sepal_length    0\n",
      "sepal_width     0\n",
      "petal_length    0\n",
      "petal_width     0\n",
      "species         0\n",
      "dtype: int64\n",
      "Data Types\n",
      "sepal_length    float64\n",
      "sepal_width     float64\n",
      "petal_length    float64\n",
      "petal_width     float64\n",
      "species          object\n",
      "dtype: object\n",
      "Data Set\n",
      "     sepal_length  sepal_width  petal_length  petal_width          species\n",
      "14            5.8          4.0           1.2          0.2      Iris-setosa\n",
      "98            5.1          2.5           3.0          1.1  Iris-versicolor\n",
      "75            6.6          3.0           4.4          1.4  Iris-versicolor\n",
      "16            5.4          3.9           1.3          0.4      Iris-setosa\n",
      "131           7.9          3.8           6.4          2.0   Iris-virginica\n",
      "Iris Dataset\n",
      "     sepal_length  sepal_width  petal_length  petal_width\n",
      "14            5.8          4.0           1.2          0.2\n",
      "98            5.1          2.5           3.0          1.1\n",
      "75            6.6          3.0           4.4          1.4\n",
      "16            5.4          3.9           1.3          0.4\n",
      "131           7.9          3.8           6.4          2.0\n",
      "Class Column\n",
      "14         Iris-setosa\n",
      "98     Iris-versicolor\n",
      "75     Iris-versicolor\n",
      "16         Iris-setosa\n",
      "131     Iris-virginica\n",
      "Name: species, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# #Data Set Reading\n",
    "# # list for column headers\n",
    "# names = ['Preg', 'Plas', 'Pres', 'Skin', 'Test', 'Mass', 'Pedi', 'Age', 'Class']\n",
    "# df = pd.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\",names=names)\n",
    "# global N,M\n",
    "# N,M=df.shape\n",
    "# df.head()\n",
    "# #To convert into Target and Attributes\n",
    "# X_Data = df.drop(\"Class\", axis=1)\n",
    "# y_Target = df[\"Class\"]\n",
    "# print(N,M)\n",
    "# print(X_Data.shape)\n",
    "\n",
    "#Titanic Data\n",
    "X_Data,y_Target=get_IrisData()\n",
    "N,M=X_Data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gZUyGajc4IjA",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# number of decision trees\n",
    "dTree = 500\n",
    "# number of features for split\n",
    "K = int(M**(1/2))\n",
    "# empty array for error rates\n",
    "error_rates_SFS, error_rates_SBS, error_rates_SRS = [], [], []\n",
    "# list to store the trees\n",
    "error_rate_SFS_10,error_rate_SBS_10,error_rate_SRS_10 = [], [], []\n",
    "\n",
    "# for loop \n",
    "for i in range(10):\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = data_split()\n",
    "    # Random forest model \n",
    "    classifier = RandomForestClassifier(n_estimators=dTree, max_features=K)\n",
    "    # fit the classifier with data\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # empty RF object for SFS\n",
    "    classifier_SFS = RandomForestClassifier()\n",
    "    error_rates_SFSMain=SFS_method(classifier_SFS,copy.deepcopy(classifier))\n",
    "    error_rate_SFS_10.append(error_rates_SFSMain)\n",
    "    \n",
    "    # copy of already created RF object for SBS\n",
    "    classifier_SBS = copy.deepcopy(classifier)\n",
    "    error_rates_SBSMain=SBS_method(classifier_SBS,copy.deepcopy(classifier))\n",
    "    error_rate_SBS_10.append(error_rates_SBSMain)\n",
    "    \n",
    "    # empty RF object for SRS\n",
    "    \n",
    "    classifier_SRS = RandomForestClassifier()\n",
    "    error_rates_SRSMain=SRS_method(classifier_SRS,copy.deepcopy(classifier))\n",
    "    error_rate_SRS_10.append(error_rates_SRSMain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation For Iris Dataset-SEQUENTIAL FORWARD SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.083333  0.083333  0.066667  0.083333  0.066667  0.066667  0.066667   \n",
       "1  0.066667  0.066667  0.066667  0.050000  0.066667  0.050000  0.050000   \n",
       "2  0.083333  0.100000  0.083333  0.066667  0.083333  0.083333  0.083333   \n",
       "3  0.050000  0.050000  0.050000  0.033333  0.033333  0.033333  0.033333   \n",
       "4  0.033333  0.050000  0.033333  0.033333  0.033333  0.033333  0.033333   \n",
       "\n",
       "        7         8         9      ...          490       491       492  \\\n",
       "0  0.066667  0.066667  0.066667    ...     0.066667  0.066667  0.066667   \n",
       "1  0.050000  0.050000  0.050000    ...     0.050000  0.050000  0.050000   \n",
       "2  0.083333  0.083333  0.083333    ...     0.100000  0.100000  0.100000   \n",
       "3  0.033333  0.033333  0.033333    ...     0.050000  0.050000  0.050000   \n",
       "4  0.033333  0.033333  0.033333    ...     0.050000  0.050000  0.050000   \n",
       "\n",
       "        493       494       495       496       497       498       499  \n",
       "0  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667  \n",
       "1  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000  \n",
       "2  0.100000  0.100000  0.100000  0.100000  0.100000  0.100000  0.100000  \n",
       "3  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000  \n",
       "4  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SFS_IRIS = pd.DataFrame(error_rate_SFS_10)\n",
    "df_SFS_IRIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation For Iris Dataset-SEQUENTIAL BACKWARD SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667   \n",
       "1  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000   \n",
       "2  0.100000  0.100000  0.100000  0.100000  0.100000  0.100000  0.100000   \n",
       "3  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000   \n",
       "\n",
       "        7         8         9      ...          490       491       492  \\\n",
       "0  0.066667  0.066667  0.066667    ...     0.066667  0.066667  0.066667   \n",
       "1  0.050000  0.050000  0.050000    ...     0.066667  0.066667  0.066667   \n",
       "2  0.100000  0.100000  0.100000    ...     0.100000  0.100000  0.100000   \n",
       "3  0.050000  0.050000  0.050000    ...     0.066667  0.066667  0.066667   \n",
       "\n",
       "        493       494       495       496       497       498       499  \n",
       "0  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667  \n",
       "1  0.083333  0.050000  0.083333  0.066667  0.066667  0.066667  0.066667  \n",
       "2  0.100000  0.100000  0.100000  0.100000  0.100000  0.100000  0.100000  \n",
       "3  0.066667  0.083333  0.083333  0.083333  0.066667  0.050000  0.066667  \n",
       "\n",
       "[4 rows x 500 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SBS_digit = pd.DataFrame(error_rate_SBS_10)\n",
    "df_SBS_digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation For Iris Dataset-SEQUENTIAL RANDOM SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.100000  0.100000  0.100000  0.116667  0.066667  0.083333  0.083333   \n",
       "1  0.083333  0.133333  0.083333  0.050000  0.066667  0.033333  0.050000   \n",
       "2  0.016667  0.050000  0.083333  0.083333  0.100000  0.100000  0.100000   \n",
       "3  0.166667  0.283333  0.033333  0.166667  0.050000  0.050000  0.033333   \n",
       "\n",
       "        7         8         9      ...          490       491       492  \\\n",
       "0  0.083333  0.083333  0.083333    ...     0.066667  0.066667  0.066667   \n",
       "1  0.050000  0.050000  0.050000    ...     0.050000  0.050000  0.050000   \n",
       "2  0.083333  0.100000  0.100000    ...     0.100000  0.100000  0.100000   \n",
       "3  0.083333  0.050000  0.083333    ...     0.050000  0.050000  0.050000   \n",
       "\n",
       "        493       494       495       496       497       498       499  \n",
       "0  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667  \n",
       "1  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000  \n",
       "2  0.100000  0.100000  0.100000  0.100000  0.100000  0.100000  0.100000  \n",
       "3  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000  \n",
       "\n",
       "[4 rows x 500 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SRS_digit = pd.DataFrame(error_rate_SRS_10)\n",
    "df_SRS_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "random_forest_paper.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
