{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "import random\n",
    "from random import randrange\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import misc\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Titanic Dataset\n",
    "#https://www.kaggle.com/c/titanic/data\n",
    "def get_titanic_data():\n",
    "    df_titanic=pd.read_csv('titanic.csv',)\n",
    "    #Remove unnecessary columns (body= Body Indentification number, Name= Name)\n",
    "    df_titanic.drop(['name','body'],1,inplace=True)\n",
    "    #Fill all the na  \n",
    "    df_titanic.cabin.fillna('unknown',inplace=True)\n",
    "    df_titanic.age.fillna(df_titanic['age'].mean(),inplace=True)\n",
    "    df_titanic.fillna(0,inplace=True)\n",
    "    #Covert nonnumeric value into numeric\n",
    "    df_titanic['sex'] = LabelEncoder().fit_transform(df_titanic['sex'])\n",
    "    df_titanic['cabin'] = LabelEncoder().fit_transform(df_titanic['cabin'].astype(str))\n",
    "    df_titanic['embarked'] = LabelEncoder().fit_transform(df_titanic['embarked'].astype(str))\n",
    "    df_titanic['home.dest'] = LabelEncoder().fit_transform(df_titanic['home.dest'].astype(str))\n",
    "    df_titanic['ticket'] = LabelEncoder().fit_transform(df_titanic['ticket'])\n",
    "    df_titanic['boat'] = LabelEncoder().fit_transform(df_titanic['boat'].astype(str))\n",
    "    # df_titanic.head()\n",
    "    # df_titanic.dtypes\n",
    "    # print(df_titanic.isnull().sum())\n",
    "    y = df_titanic['pclass']\n",
    "    X = df_titanic.drop(\"pclass\", axis = 1)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Train_Test_Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(X_Data,y_Target):    \n",
    "    #To split the dataset into 3 parts   \n",
    "    X_train, X_test, y_train, y_test= train_test_split(X_Data, y_Target, test_size=0.4)\n",
    "    X_train, X_val, y_train, y_val= train_test_split(X_train, y_train, test_size=0.5)\n",
    "    \n",
    "    return X_train,X_val,X_test,y_train,y_val,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=get_titanic_data()\n",
    "X_train,X_val,X_test,y_train,y_val,y_test=data_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train.shape)\n",
    "# print(X_val.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_val.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Methods and submethods declaration for genetic algorithm optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method used to split the initial random forest into random forest vector population\n",
    "def partition_gene_to_chromosome(listin, n):\n",
    "    random.shuffle(listin)\n",
    "    return [listin[i::n] for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to determin the best fit parents\n",
    "def call_population_fitness(randomForest_population):\n",
    "    \n",
    "    fitnesslist=[]\n",
    "    for rf in randomForest_population:\n",
    "        fitness=rf.score(X_val,y_val)\n",
    "        fitnesslist.append(fitness)\n",
    "\n",
    "    fitness_matrix = { i : fitnesslist[i] for i in range(0, len(fitnesslist) ) }\n",
    "    return fitness_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fuction to select the parent population\n",
    "def call_population_selection(fitness_matrix,randomForest_population,parents_number):\n",
    "    fitness_ordered=sorted(fitness_matrix.items(), key=itemgetter(1),reverse=True)\n",
    "    selected_chromRF_Index=list(list(zip(*fitness_ordered))[0])[:parents_number]\n",
    "    print(selected_chromRF_Index)\n",
    "    selected_rf_population=[randomForest_population[i] for i in selected_chromRF_Index]\n",
    "    \n",
    "    return selected_rf_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sub Function for cross over\n",
    "def get_offcross_spring(rf_chromosome1,rf_chromosome2,cross_over_point):\n",
    "    rf_chromosome1.estimators_=rf_chromosome1.estimators_[0:cross_over_point]\n",
    "    rf_chromosome2.estimators_=rf_chromosome2.estimators_[cross_over_point:]\n",
    "    modified_estimators=rf_chromosome1.estimators_+rf_chromosome2.estimators_\n",
    "    rf_chromosome1.estimators_=modified_estimators\n",
    "    return rf_chromosome1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Crossover Function\n",
    "def call_crossover_generation(selected_rf_population,crossover_per_gen):\n",
    "    offsprings_gen = []\n",
    "    # The crossoverpoint\n",
    "    cross_over_point = np.uint8(len(selected_rf_population[1])/2)   \n",
    "    \n",
    "    for k in range(int(crossover_per_gen)):\n",
    "        # Crossoverindex of the first parent\n",
    "        parent1_index = k % len(selected_rf_population)\n",
    "        # Crossoverindex of the seconf parent\n",
    "        parent2_index = (k+1) % len(selected_rf_population)\n",
    "        offspring=get_offcross_spring(selected_rf_population[parent1_index],selected_rf_population[parent1_index],cross_over_point)\n",
    "        offsprings_gen.append(offspring)\n",
    "    return offsprings_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to get the mutated chromosomes\n",
    "def get_mutation_gen(randomForest,selected_rf_population,mutation_per_gen):\n",
    "    offsprings_gen = []\n",
    "#     print(offsprings_gen)\n",
    "    rf_for_mutation=[]\n",
    "    for k in range(int(mutation_per_gen)):  \n",
    "        # Randomly choose a chromosome for mutation.\n",
    "        parent1_index = k % len(selected_rf_population)\n",
    "        rf_for_mutation=random.choice(selected_rf_population)\n",
    "#         print(k,\"k\")\n",
    "#         print(rf_for_mutation)\n",
    "#         print(len(rf_for_mutation))\n",
    "        #Randomly choose one of the gene for mutation\n",
    "        gene_for_mutation = random.choice(rf_for_mutation.estimators_)\n",
    "#         print(gene_for_mutation) \n",
    "        rf_for_mutation.estimators_.remove(gene_for_mutation)\n",
    "#         print(len(rf_for_mutation.estimators_))\n",
    "        slctimpurity_df=random.choice(randomForest)\n",
    "#         print(slctimpurity_df)\n",
    "        rf_for_mutation.estimators_.append(slctimpurity_df)\n",
    "        offsprings_gen.append(rf_for_mutation)\n",
    "    \n",
    "    return offsprings_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=3, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M,N=X.shape\n",
    "F=int(N**(1/2))\n",
    "\n",
    "#Total number of decision trees all random forest\n",
    "initial_population=1000\n",
    "initial_population_list=list(range(0,initial_population))\n",
    "#Total number of chromosome(No of sub random forest for genetic algorithm)\n",
    "n=100\n",
    "cross_over_rate=0.9\n",
    "mutation_rate=0.1\n",
    "number_of_gen=100\n",
    "crossover_per_gen=(cross_over_rate*n)\n",
    "mutation_per_gen=(mutation_rate*n)\n",
    "print(crossover_per_gen)\n",
    "#Number of parents for next generation\n",
    "parents_number=50\n",
    "# Random forest model \n",
    "# Generating first population of raandom forest\n",
    "randomForest = RandomForestClassifier(n_estimators=initial_population,max_features=F)\n",
    "randomForest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_forest_chromosome=partition_gene_to_chromosome(initial_population_list,n)\n",
    "# print(sub_forest_chromosome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of initial population (chromosomes)\n",
    "\n",
    "randomForest_population=[]\n",
    "for chrom in range(n):\n",
    "    \n",
    "    rf_classifier=RandomForestClassifier(n_estimators=len(sub_forest_chromosome[chrom]))\n",
    "    rf_classifier.estimators_=[]\n",
    "    for gene in sub_forest_chromosome[chrom]:\n",
    "        rf_classifier.estimators_.append(randomForest.estimators_[(gene-1)])    \n",
    "    \n",
    "    rf_classifier.classes_=randomForest.classes_\n",
    "    rf_classifier.n_classes_=randomForest.n_classes_\n",
    "    rf_classifier.n_outputs_=randomForest.n_outputs_ \n",
    "    rf_population=randomForest_population.append(rf_classifier)\n",
    "# print(randomForest_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation Number:  0\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "Estimator not fitted, call `fit` before exploiting the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-d81d6ac6a5fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Generation Number: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# To measure the fitness of each chromosome\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mfitness_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcall_population_fitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandomForest_population\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# To select the best parents for next generation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-2f19c369b5a9>\u001b[0m in \u001b[0;36mcall_population_fitness\u001b[1;34m(randomForest_population)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfitnesslist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrandomForest_population\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mfitness\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mfitnesslist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \"\"\"\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    541\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         \"\"\"\n\u001b[1;32m--> 543\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             raise NotFittedError(\"Estimator not fitted, \"\n\u001b[0m\u001b[0;32m    360\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Estimator not fitted, call `fit` before exploiting the model."
     ]
    }
   ],
   "source": [
    "for gen in range(number_of_gen):\n",
    "    print(\"Generation Number: \", gen)\n",
    "    # To measure the fitness of each chromosome\n",
    "    fitness_matrix=call_population_fitness(randomForest_population)\n",
    "\n",
    "    # To select the best parents for next generation\n",
    "    next_gen_parents = call_population_selection(fitness_matrix,randomForest_population,parents_number)\n",
    "    \n",
    "    # Crossover for generating offspring\n",
    "    crossover_offsprings = call_crossover_generation(next_gen_parents,crossover_per_gen)\n",
    "    print(next_gen_parents)\n",
    "    # Mutation for the generated offspring\n",
    "    mutated_offspring = get_mutation_gen(randomForest,next_gen_parents,mutation_per_gen)\n",
    "\n",
    "    # New population for next generation\n",
    "    next_population=[]\n",
    "    next_population.append(crossover_offsprings)\n",
    "    next_population.append(mutated_offspring)\n",
    "    len(next_population)\n",
    "    randomForest_population=next_population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
